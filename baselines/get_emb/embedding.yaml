project_name: group-alignment

model: ./recover_weights_alpaca_7b
#model: ./llama-2-13b-chat-hf
n_qs: 1
use_int8: True
seed: 42
save_path: ./baselines/get_emb/ # TODO: change to your path
oqa_dataset_path: ./OQA_data # TODO: change to your path
batch_size: 4
prompt_format: None
dataset:  globalqa #opinionqa

lora:
  r: 1
  lora_alpha: 32
  lora_dropout: 0.1
  bias: none
  task_type: CAUSAL_LM
