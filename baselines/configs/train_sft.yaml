project_name: "group-alignment-sft-anthropic-alpaca"
expid: None

model_ckpt: /localhome/data/ckpts/shared/recover_weights_alpaca_7b
prompt_format: alpaca
use_int8: True

lora:
  r: 12
  lora_alpha: 32
  lora_dropout: 0.05
  bias: none
  task_type: CAUSAL_LM

data:
  task: sft_pergroup
  #dataset: opinion_qa
  dataset: anthropic_global_opinions
  oqa_datapath: ./OQA_data/ 
  group_idx: 0 # finetune which group
  CONTEXT: default # [default, steer-portray, steer-qa]
  train_nq: 15 # how many questions are used to train.
  

trainer:
  num_train_epochs: 2000
  output_dir: "./finetune_baselines_SFTmodels/" #set to model saving directory
  reproduce_exp_log_dir: "./exp_infolog/" # for saving qkeys used for train and test
  learning_rate: 3e-4
  weight_decay: 0.01
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 8
  bf16: True


seed: 0
