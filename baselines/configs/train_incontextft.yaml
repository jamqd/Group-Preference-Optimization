project_name: group-alignment-sft
expid: None
model_ckpt: /localhome/data/ckpts/shared/recover_weights_alpaca_7b
prompt_format: llama2
use_int8: True

lora:
  r: 12
  lora_alpha: 32
  lora_dropout: 0.05
  bias: none
  task_type: CAUSAL_LM

data:
  task: meta_SFT # in-context-finetuning
  #dataset: opinion_qa
  dataset: anthropic_global_opinions
  oqa_datapath: ./OQA_data/ 
  group_split: 0.4 # meta train group percentage
  CONTEXT: default 
  train_nq: 20 # defines the number of context questions
  
trainer:

  num_train_epochs: 10000
  output_dir: "./finetune_baselines_SFTmodels/" #set to model saving directory
  reproduce_exp_log_dir: "./exp_infolog/" # for saving qkeys used for train and test
  learning_rate: 1e-4
  weight_decay: 0.01
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 8
  bf16: True


seed: 0